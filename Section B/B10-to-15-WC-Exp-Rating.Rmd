---
title: "Work Comp Experience Rating papers"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 4
---

## Purpose of Experience Rating

Relates an insured's premium for $policy_t$ to their own loss experience from $policy_{t-1}$

$\begin{array}{lcccc}
  \text{Standard Premium} &= &\textbf{Modified Premium} &\times &\text{Schedule Mod Factor} \\
  &= &\left( \textbf{Manual Premium} \times \textbf{Experience Mod Factor} \right) &\times &\text{Schedule Mod Factor} \\
\end{array}$

Mostly just assumes Sch Mod = 1 $\therefore$ Standard Premium = Modified Premium

Experience rating is suitable for WC $\because$ lots of variations within a classification plan due to level of control over safety practices

Experience rating helps further distinguish between risks within a classification for things that typically doesn't have a separate rating for, e.g. Compensation, variation in premise, operating processes, materials, managements, employee morale, claim consciousness, relation to the community, etc

Credibility of actual loss experience depends on:

* Size of the insured (e.g. payroll)
* $\sigma$ between the loss experience of risks within a classification
    * Experience rating is more useful when the class plan doesn't sufficiently explain $\sigma$ in loss experience between risks
    
## Goals of Experience Ratings <span style="color:red;background-color:yellow">Important Concepts</span>

1. **Predictive accuracy** $\Rightarrow$ Individual risk equity  
Degree of charge based on past experience should be the degree to which it is predictive of future losses $\Rightarrow$ Insureds charged more closely relates to their loss potential $\Rightarrow$ Ensures equity, rates not unfairly discriminatory

2. **Safety incentive**  
Give insured financial incentive for loss control

3. **Enhance market competition**
Increase availability of insurance since experience rating helps guarantee an equal profit potential on all risks after the application of the experience mod

**Balance between 1. and 2.** since 2. will charge for all losses while 1. will only charge for non-random prior losses that are predictive of future loss potential

## Types of Experience Rating Plans

Maximize predictive accuracy $\Rightarrow$ Minimize between predictedand actual losses

Use $\mathrm{E}[error^2] since it's solvable and penalizes large errors

Linearity contraint: E-mod has to be a linear function of losses

* Simplify math and make them more understandable

### No-split Plans

No subdivision of losses

$\begin{array}{llll}
  Mod &= \dfrac{\text{Modified Expected Losses}}{\text{Expected Losses}} &= \dfrac{ZA + (1-Z)E}{E} & \cdots (1) \\
  & &= 1 + Z \left( \dfrac{A - E}{E} \right) \\
  & &= \dfrac{A + K_E}{E + K_E} \\
\end{array}$

* **Credibility**: $Z = \dfrac{E}{E + K_E}$

***

Alternatively, from $(1) \times \frac{P}{P}$ you get the Surety Association Plans formula:

$Mod = (1 - Z) + Z \dfrac{P}{E} \times \dfrac{A}{P}$

* $P$: Standard Premium

* $(1-Z)$: Premium Modifier

* $Z \dfrac{P}{E}$: Adjusted Loss Modifier

* $\dfrac{A}{P}$: Adjusted Loss Ratio

***

####$K_E$: Credibility Constant

$K_E$ could be:

* A constant; or
* $f(E)$; or
* Manually picked for desired responsiveness (NCCI)

Condition for $K_E$

1. $0 \leq Z \leq 1$

2. $\frac{d}{dE}(Z) \geq 0$

    * Size of risk $\uparrow$ $\Rightarrow$ $Z$ can't go down

3. $\frac{d}{dE}\left(\frac{Z}{E}\right) < 0$

    * Size of risk $\downarrow$ $\Rightarrow$ % charge for any loss $\downarrow$
    
    * $Z$ can't $\uparrow$ faster than the size $\uparrow$
    
    * $\neq$ $Z$ increase at a decreasing rate

![alt text](figures/Exam 8 B8 - 15 - 5.png)

#### Problems of no split plans

Problematic for highly skewed, heavy-tailed distributions such as that of Work Comp claims

**Solution based on Venter's Argument:**

Split losses into primary and XS, the dist^n^ of each component becomes less heavy-tailed and more predictable than using unsplit losses

**Correct Argument:**

Splitting losses into primary and XS does NOT make each more predictable. E.g. it is much easier to price a ground-up policy than an excess policy, since there is much greater uncertainty around XS losses

Split plan works better because:

* Substantial parameter risk due to the claim count uncertainty that impacts mostly the primary layer

* Process risk is due to the volatility of severity that impacts mostly the XS layer

* Split plans are more effective when most of the parameter risk goes to one portion of the split while most of the process risk goes to a separate portion

* [Source](http://www.variancejournal.org/issues/?fa=article&abstrID=7015)

### Split Plans

Subdivision losses into *primary* and *XS* components and $\mathrm{E}[error^2]$ is minimized seperately

**Primary:**

* Reflects claim frequency
* Receives most weight

**XS:**

* Reflects claim severity

***

<span style="color:red;background-color:yellow">Memorize</span>

$\begin{array}{llccc}
  Mod &= &\frac{1}{E}[Z_p A_p + (1-Z_p)E_p] &+ &\frac{1}{E}[Z_e A_e + (1-Z_e)E_e] \\
  &= 1 + &Z_p \left( \dfrac{A_p - E_p}{E} \right) &+ &Z_e \left( \dfrac{A_e - E_e}{E} \right) \\
  &= 1 + &\dfrac{A_p - E_p}{E + K_p} &+ &\dfrac{A_e - E_e}{E + K_e} \\
\end{array}$

* $Z_p = \dfrac{E}{E + K_p}; Z_e = \dfrac{E}{E + K_e}$

***

**Perryman's First Formula:**

$Mod = \dfrac{A_p + W A_e + (1 - W)E_e + B}{E_{total} + B}$ <span style="color:red;background-color:yellow">Memorize</span>

* $B = (1 - W)K > 0$

* $Z_p = \dfrac{E}{E + B}$

* $Z_e = W Z_p

* Weight: $W = \dfrac{E + K_p}{E + K_e}$
    * $0 < W < 1$
    * $W$ never $\uparrow$ given $\downarrow$ $E$

* $B = K_p$

* $E_{total} = E_p + W E_e + (1-W)E_e$

* Used by NCCI since 1940 change

***

#### Single Split Plans

$A_p = 
  \begin{cases}
    A & A \leq C \\
    C & A > C \\
  \end{cases}$

$A_e = \hat{A} - A_p$

* $\hat{A}$: Capped loss that are too large that have no predictability
    * Cap by SAL

#### Multi-split Plans

Multiple incremental amounts of losses; Decreasing portion (by factor of $(1-d)^i$) of each successive increment is considered to be primary

$A_p = I + \sum\limits_{i=1}^{N-1}(1-d)^i I + (1-d)^N (A-NI)$

* $N$: number of complete increments
* $I$: incremental loss \$
* $d$: rate of discount
* Max $A_p = \frac{I}{d}$

$A_e = \hat{A} - A_p$

## History of NCCI Experience Rating

| Time Period | Highlights |
| ----------- | ---------- |
| Pre-1940    | No-split   |
| 1940        | Multi-split: $I = \$500, d = \frac{1}{3}$; $B$, $K$ $\downarrow$ linearly to risk size |
| 1961        | Single-split: @ \$2,000 w/ max $A_p = \$10,000$ |
| 1991        | Single-split: @ \$5,000 w/ max $A_p = \$5,000$;  $B$, $K$, $\uparrow$ non-linearly to risk size |
| 1998        | $\downarrow$ Med-only weight; $\uparrow$ XS weight; inflation sensitive split |

### Pre-1940

No-split

$Mod = \dfrac{A + K_E}{E + K_E}$

### 1940 Changes

Multi-split

$Mod = \dfrac{A_p + W A_e + (1 - W)E_e + B}{E_{total} + B}$

* $I$ = \$500
* $d$ = $\frac{1}{3}$

Tables of $B$ and $W$ based on risk size:

* Prevent large swings in E-mod for small insured
* $Z$ can be 1 for large insured

As risk size $\uparrow$:

* $B$, $K$, $\downarrow$
* $W$ $\uparrow$

### 1961 Changes

$A_p =
  \begin{cases}
    A & A \leq 2,000 \\
    \dfrac{10,000A}{A + 8,000} & A > 2,000 \\
  \end{cases}$
  
Max $A_p = 10,000$

$A_e = \hat{A} - A_p$

* $\hat{A}$ capped by max ratable value

### 1991 Changes

1. Simplified single split
2. $B$, $K$, $\uparrow$ non-linearly with premium
    * $W$ still $\uparrow$ with premium

$A_p =
  \begin{cases}
    A & A \leq 5,000 \\
    5,000 & A > 5,000 \\
  \end{cases}$
  
$A_e = \hat{A} - A_p$

Reason for change:  
Too much credibility given to large risk and not enough for small risk $\Rightarrow$ <10K and >100K becamse preferred business

Theoretically:

$B$, $K$ being constant assume that larger insureds are more stable than smaller insureds, and thus the variance of standard loss ratios should be inversely $\propto$ to risk size

Reality:

Variance did not decrease that quickly

**Impact:**<span style="color:red;background-color:yellow">Important Memorize</span>

| Samll risks $Z_p$  | Small risks $Z_e$      |
| ------------------ | ---------------------- |
| $\uparrow$         | $\uparrow; \: Z_e > 0$ |

| Large risks $Z_p$                | Large risks $Z_e$                |
| -------------------------------- | -------------------------------- |
| $\downarrow;\: max \: Z_p = 91\%$ | $\Downarrow;\: max \: Z_e = 57\%$ |

For large risk, $\because$ $Z_e \: \downarrow \: > Z_p \: \downarrow \: \Rightarrow$ Effectively gave primary losses more weight for large risks

New plan performed better for small and large risks, and performed equally well for medium sized risks based on quintiles test

### 1998 Change
<span style="color:red">Not in 2015 syllabus Concepts</span>

1. $\downarrow$ $Z$ on Med-only by about 70%
    * Deincentivise not reporting med-only clais
    * Lowered ELRs and D-ratios to maintain balance
2. $\uparrow$ $Z_e$ as premium $\uparrow$
    * Promote safety incentive
3. Inflation sensitive split point

## Testing the Experience Rating Plan  
<span style="color:red;background-color:yellow">Important know all test</span>

Main challenge: Determining the proper $Z$ to give to prior losses

Correct $Z$ $\Rightarrow$ maximizing predictive accuracy of plan

Dorweiler's 2 conditions for correct credibility:

1. Necessary: $PLR_i = PLR_j \forall \: i,j$ credit and debit risks in prospective period (each random subgroup as well)
2. Sufficient: $\nexists \: \subset$ risks with $PLR_i \neq PLR_j$ in prospective period

3 test for predictive accuracy of the plan; All tests are performed for each size group separately

### Test 1: Dorweiler's Test

<span style="color:green">2006 Q23, 2013 Q8</span>

**Setup:**

1. *Sort* risks by *mods* in *increasing* order
2. *Group* into subdivisions
3. For each subdivisions: calculate *manual* and *standard* LR using weighted averages by respective premium (w/ actual loss) <span style="color:red;background-color:yellow">Not super sure what to weight</span> 
    * If no premium: Manual LR $\Rightarrow$ Use $\dfrac{Loss_{Actual}}{Loss_{Expected}}$; Standard LR $\Rightarrow$ Use $\dfrac{Loss_{Actual}}{Loss_{Modified Expected}}$

**For plan performing ideally:**

* Max dispersion in manual LRs (Identifies)
    * Plan is good at identifying risk difference
* Equal standard LRs (Corrects)
    * Shows plan corrects for risk difference
* Same as Venter's convergence test
* If there's increasing trend in Standard LR $\Rightarrow$ Too little credibility is applied; Vice versa

### Test 2: Gillam's Quintiles Test

Only for comparing 2 or more plans

**Setup:**

1. *Sort* risks by *mod* in *increasin* order
2. *Group* into **5 quintiles**
3. For each quintiles: calculate *manual* and *standard* LR using weighted averages by manual premium
4. *Quintiles test statistics:* $\dfrac{\sigma^2(Standard \:  LR)}{\sigma^2(Manual \: LR)}$

**For plan performing ideally:**

Low test statistics

### Test 3: Efficiency Test

Only for comparing 2 or more plans

**Setup:**

1. *No* sorting necessary
2. *No Grouping* within the size group
    * Recall all 3 test are done for each size group
3. For each group, calculate *manual* and *standard* LR
4. *Efficiency test statistics:* $\dfrac{\sigma^2(Standard \:  LR)}{\sigma^2(Manual \: LR)}$

**For plan performing ideally:**

Low test statistics

* Better risk reduction in risk LR variance

***

For each test, if no premium data available:

* Replace manual LR $\Rightarrow$ Use $\dfrac{Loss_{Actual}}{Loss_{Expected}}$

* Replace standard LR $\Rightarrow$ Use $\dfrac{Loss_{Actual}}{Loss_{Modified Expected}}$

### Example for Quintiles and Efficiency Tests

```{r echo = FALSE, message=FALSE}
library(dplyr)
library(scales)
library(knitr)

d1 <- data_frame(
  "Pol No" = seq(1,10,1),
  "Manual LR" = c(0.62, 0.65, 0.69, 0.68, 0.77, 0.81, 0.85, 0.81, 0.85, 0.93),
  "Plan A E Mod" = c(0.75, 0.80, 0.85, 0.90, 0.95, 1.00, 1.1, 1.15, 1.2, 1.25),
  "Plan B E Mod" = c(0.68, 0.84, 0.95, 0.78, 1.0, 1.08, 1.00, 1.11, 1.17, 1.22)
)

d1 <-
  d1 %>% 
  mutate(`Plan A Standard LR` = `Manual LR`/`Plan A E Mod`,
         `Plan B Standard LR` = `Manual LR`/`Plan B E Mod`,
         `Manual LR` = `Manual LR`)
```

`r kable(d1, align = 'l')`

#### Quintiles Test:

***1. Sort by mod and group into 5 quintiles***

```{r}
d1_1 <- 
  d1 %>%
  mutate(QuintileA = ntile(`Plan A E Mod`, 5),
         QuintileB = ntile(`Plan B E Mod`, 5))
```

`r kable(d1_1, align = 'l')`

***2. Calculate Weighted average manual and standard LR***

```{r}
d1_2_a <-
  d1_1 %>%
  group_by(QuintileA) %>%
  summarize(`Plan A Manual Avg LR` = mean(`Manual LR`),
            # Straight average
            `Plan A Standard Wtd Avg LR` = weighted.mean(`Plan A Standard LR`, `Manual LR`)
            # Wtd by Manual LR
  )
```

`r kable(d1_2_a, align = 'l')`

```{r}
d1_2_b <-
  d1_1 %>%
  group_by(QuintileB) %>%
  summarize(`Plan B Manual Avg LR` = mean(`Manual LR`),
            # Straight average = Wtd by Manual LR
            `Plan B Standard Wtd Avg LR` = weighted.mean(`Plan B Standard LR`, `Manual LR`)
            # Wtd by Manual LR
  )
```

`r kable(d1_2_b, align = 'l')`

***3. Quintile Statistics***

```{r}
d1_3_a <-
  d1_2_a %>%
  summarize(`Manual LR Var` = var(`Plan A Manual Avg LR`)*(nrow(.)-1)/(nrow(.)),
            `Standard LR Var` = var(`Plan A Standard Wtd Avg LR`)*(nrow(.)-1)/(nrow(.)))

kable(d1_3_a, align = 'l')

```

Quintiles Test Statistics for Plan A = $\dfrac{\sigma^2(\text{Standard LR})}{\sigma^2(\text{Manual LR})}$ = `r d1_3_a[[2]]/d1_3_a[[1]]`

```{r}
d1_3_b <-
  d1_2_b %>%
  summarize(`Manual LR Var` = var(`Plan B Manual Avg LR`)*(nrow(.)-1)/(nrow(.)),
            `Standard LR Var` = var(`Plan B Standard Wtd Avg LR`)*(nrow(.)-1)/(nrow(.)))

kable(d1_3_b, align = 'l')

```

Quintiles Test Statistics for Plan B = $\dfrac{\sigma^2(\text{Standard LR})}{\sigma^2(\text{Manual LR})}$ = `r d1_3_b[[2]]/d1_3_b[[1]]`

$\because$ Plan A has a lower test statistics $\therefore$ Plan A is more effective

#### Efficiency Test:

Calculate the variance of the manual LR and standard LR under the 2 plan with out any sorting and grouping

```{r}
d2 <-
  d1_1 %>%
  summarize(`Manual LR Var` = var(`Manual LR`)*(nrow(.)-1)/(nrow(.)),
            `Plan A Standard LR Var` = var(`Plan A Standard LR`)*(nrow(.)-1)/(nrow(.)),
            `Plan B Standard LR Var` = var(`Plan B Standard LR`)*(nrow(.)-1)/(nrow(.)))

kable(d2, align = 'l')
```

Quintiles Test Statistics for Plan A = $\dfrac{\sigma^2(\text{Standard LR})}{\sigma^2(\text{Manual LR})}$ = `r d2[[2]]/d2[[1]]`

Quintiles Test Statistics for Plan A = $\dfrac{\sigma^2(\text{Standard LR})}{\sigma^2(\text{Manual LR})}$ = `r d2[[3]]/d2[[1]]`

$\because$ Plan A has a lower test statistics $\therefore$ Plan A is more effective

## Data Used for Experience Rating

