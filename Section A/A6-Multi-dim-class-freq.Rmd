---
title: Multi-Dimensional Credibility to Estimate Class Frequency Vectors in WC
author: "Couret & Venter"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 4
---

## Cliff's Summary

Understand the [key idea](#keyidea)

3 main steps + test

1. Calculate the frequencey [relativities](#rel) by HG and by class
2. [Credibility](#credibility) weight the HG and class to get credibility weighted relativies
    
    * $\hat{ {\color{blue}\boxdot}}_i = {\color{red}\Box}_h + b_{ {\color{blue}\boxdot}, i}(V_i - V_h) + c_{ {\color{blue}\boxdot}, i}(W_i - W_h) + d_{ {\color{blue}\boxdot}, i}(X_i - X_h) + e_{ {\color{blue}\boxdot}, i}(Y_i - Y-h)$
    
3. Get the [expected XS loss](#xsloss)
4. Test if it's any imporvement

Know the [SSE](#SSE) test and [Quintiles](#quintiles) test

* Holdout is calculated same as raw

## Types of Exam Questions  
<span style="color:green">Questions a bit thin</span>

Quintiles Test

* 2011 Q2
    * How do you know they are the numbers from step 3?
* 2012 Q5a
* 2014 Q1 $\star$ (interpretation)
* Practice 4
    * Revisit the answer to make sure it ties to the notes

Expected XS loss

* 2012 Q5b $\star\star$
    * Make sure you understand this
    * See [TIA](http://www.theinfiniteactuary.com/mb/viewtopic.php?f=18024&t=12645)

Ties to A4 shifting risk parameters

* 2013 Q3d $\star$

SSE

* 2013 Q3c

Holdout

* 2013 Q3a,b

Tie to A1 risk classification principles

* 2014 Q4 $\star$

1D vs multi-D credibility formula

* Practice 2

CREDIBILITY WEIGHTED ESTIMATE

* With the credibility factors given
* Get the class level relativity
* Get the HG level (for all the class pretty much) relativity
* $\hat{ {\color{blue}\boxdot}}_i = {\color{red}\Box}_h + b_{ {\color{blue}\boxdot}, i}(V_i - V_h) + c_{ {\color{blue}\boxdot}, i}(W_i - W_h) + d_{ {\color{blue}\boxdot}, i}(X_i - X_h) + e_{ {\color{blue}\boxdot}, i}(Y_i - Y-h)$

COEFFICIENT MATRIX SETUP

* Skipped

CRED ESTIMATE QUINTILES TEST

1. Sort rel for all classes increasing order and cut into 5 quintiles
2. For training set: For each quintile, get:
    a. observed rel to TT
    b. credibility weighted rel to TT
    c. get ratio of (a) with HG rel
    d. get ratio of (c) with HG rel
3. For testing set: For each quintile, get:
    e. observed rel to TT
    f. get ratio of (e) with HG rel
4. Get statistics for each test summing across the 5 quintile
    * Hold vs HG: $\sum_{quintiles} [(f) - 1]^2$
    * Hold vs observed: $\sum_{quintiles} [(f) - (a)]^2$
    * Hold vs cred: $\sum_{quintiles} [(f) - (d)]^2$

## Intro

Price XS and retro rated WC with ELFs (by state + limit)

**Challenges:**  
ELFs hard to estimate since losses driven by small \# of very large claims

**Solution:**  
Use correlations between different injury types to build a model based on less-severe injuries for which more data exists

**Key idea:**  
<a name="keyidea"></a>  
Since the physical circumstances are similar for significant injury types, claim frequencies between those injury types are correlated

* Focus on the frequencies relativities

* Same accident can produce any injuries $\Rightarrow$ Correlation between relative frequency for different injury types

* Can use more data (from smaller injury) to better predict larger claims from more infrequent types

* Physical circumstances underlying various injury types are correlated, and those correlations are used to gain additional information in estimating credibility
weighted claim frequencies by injury type

**Corollary:**  
This also shows that the current NCCI practice of using the same ELFs for all classes within a hazard group can be further refined

* NCCI estimates excess ratios for each injury type separately, and does not use information about correlations between injury types

## Injury Types Definition

In the order of increasing severity  
(Frequency generally goes $\downarrow$ as you move down the list, except PT is more severe than Fatal)

$\begin{array}{lll}
  \text{Med} &= \text{Med Only}\\
  \text{TT} &= \text{Temporary Total} &= m\\
  \text{Minor PP} &= \text{Minor Permanent Partial} &= y\\
  \text{Major PP} &= \text{Major Permanent Partial} &= x\\
  \text{PT} &= \text{Permanent Total} &= w\\
  \text{F} &= \text{Fatal} &= v\\
\end{array}$

Letter = \# of claims

## Variables in the Analysis  
<a name="rel"></a>

Looks at $\dfrac{\text{Claim Counts}_{Type}}{\text{Claim Counts}_{TT}}$
  
* For every class code within the HG
* Look at TT claim as an exposure that could produce more severe claim

| ${\color{red}\Box}$ | ${\color{blue}\boxdot}$ | ${\color{green}\boxtimes}$  |
| ------ | --------- | ------------ |
| V      | v         | F Claims     |
| W      | w         | PT Claims    |
| X      | x         | Major Claims |
| Y      | y         | Minor Claims |

### For class code $i$ in year $t$

\# of TT **claims** in *class* $i$ in *year* $t$

* $m_{i,t} = \text{# of TT claims in class code } i \text{ in year } t$
    * $i = 1, \ldots, R$  
        * $R = \text{# of classes in HG }h$
    * $t = 1, \ldots, N$  
        * $N = \text{# of years in sample}$

\# of TT **claims** in *class* $i$

* $m_i = \sum\limits_{t=1}^N m_{i,t}$

***

Claim count **relativity** by *class* $i$ and *year* $t$

* ${\color{red}\Box}_{i,t} = \dfrac{\text{# of } {\color{green}\boxtimes} \text{ in class } i \text{ in year } t}{m_{i,t}}$

Claim count **relativity** by *class* $i$

* ${\color{red}\Box}_i = \dfrac{\sum\limits_{i=1}^N m_{i,t}{\color{red}\Box}_{i,t}}{m_i}$

### For HG $h$ in year $t$

\# of TT **claims** in *HG* $h$ in *year* $t$

* $m_{h,t} = \text{# of TT claims in HG } h \text{ in year } t$

\# of TT **claims** in *HG* $h$

* $m_h = \sum\limits_{t=1}^N m_{h,t} = \sum\limits_{i=1}^R\sum\limits_{t=1}^N m_{i,t}$

***

Claim count **relativity** by *HG* $h$ and *year* $t$

* ${\color{red}\Box}_{h,t} = \dfrac{\text{# of } {\color{green}\boxtimes} \text{ in HG } h \text{ in year } t}{m_{h,t}}$

Claim count **relativity** by *HG* $h$ and *year* $t$

* ${\color{red}\Box}_h = \dfrac{\sum\limits_{i=1}^N m_{h,t}{\color{red}\Box}_{h,t}}{m_h}$

**Assumes** variance ${\color{red}\Box}_i$ decreases as $m_i$ increases

## The Multi-Dimensional Credibility Procedure  
<span style="color:red;background-color:yellow">Hard to test</span>

**Goal:**  
Estimate population mean using credibility weighted $V_i, W_i, X_i, Y_i$ $\Rightarrow$ $v_i, w_i, x_i, y_i$

Find credibility factors $b_{ {\color{blue}\boxdot},i}, c_{ {\color{blue}\boxdot},i}, d_{ {\color{blue}\boxdot},i}, e_{ {\color{blue}\boxdot},i}$

***

### Credibility weighted relativities  
<a name="credibility"></a>

$\hat{ {\color{blue}\boxdot}}_i = {\color{red}\Box}_h + b_{ {\color{blue}\boxdot}, i}(V_i - V_h) + c_{ {\color{blue}\boxdot}, i}(W_i - W_h) + d_{ {\color{blue}\boxdot}, i}(X_i - X_h) + e_{ {\color{blue}\boxdot}, i}(Y_i - Y-h)$

* If credibilities are 0 $\Rightarrow$ Estimate = HG ratios ${\color{red}\Box}_h$

***

### Credibility factors

To solve for $b_{ {\color{blue}\boxdot},i}, c_{ {\color{blue}\boxdot},i}, d_{ {\color{blue}\boxdot},i}, e_{ {\color{blue}\boxdot},i}$ for a **given Injury Type** ${\color{blue}\boxdot}$, solve the matrix below:

$\left[
  \begin{array}{c}
    Cov(V_i, {\color{blue}\boxdot}_i)\\
    Cov(W_i, {\color{blue}\boxdot}_i)\\
    Cov(X_i, {\color{blue}\boxdot}_i)\\
    Cov(Y_i, {\color{blue}\boxdot}_i)\\
  \end{array}
\right] = 
\left[
  \begin{matrix}
    Var(V_i) & Cov(V_i W_i) & Cov(V_i, X_i) & Cov(V_i, Y_i)\\
    Cov(W_i, V_i) & Var(W_i) & & \vdots\\
    Cov(X_i, V_i) & & \ddots & \vdots\\
    Cov(Y_i, V_i) & \cdots & \cdots & \vdots\\
  \end{matrix}
\right] \times
\begin{bmatrix}
  b_{ {\color{blue}\boxdot},i}\\
  c_{ {\color{blue}\boxdot},i}\\  
  d_{ {\color{blue}\boxdot},i}\\
  e_{ {\color{blue}\boxdot},i}\\
\end{bmatrix}$

***

**Variance of the Hypothetical Mean Vector**

$Cov({\color{red}\Box}_i, {\color{blue}\boxdot}_i) = \widehat{\text{VHM}}_{\color{red}\Box} = \dfrac{\sum\limits_{i=1}^R m_i ({\color{red}\Box}_i - {\color{red}\Box}_h)^2 - (R - 1)\widehat{\text{EPV}}_{\color{red}\Box}}{m_h - m_h^{-1}\sum\limits_{i=1}^R m_i^2}$

***

**Variance-covariance Matrix**

$Var({\color{red}\Box}_i) = \dfrac{\widehat{\text{EPV}}_{\color{red}\Box}}{m_i} + \widehat{\text{VHM}}_{\color{red}\Box}$

* $\widehat{\text{EPV}}_{\color{red}\Box} = \dfrac{\sum\limits_{i=1}^R \sum\limits_{i=1}^N m_{i,t}({\color{red}\Box}_{i,t} - {\color{red}\Box}_i)^2}{R(N - 1)}$

$\begin{align}
Cov({\color{red}\Box}_i,{\color{magenta}\Box}_i) &= Cov({\color{red}\boxdot}_i,{\color{magenta}\Box}_i)\\
  &= Cov({\color{red}\Box}_i,{\color{magenta}\boxdot}_i)\\
  &= \mathrm{E}[({\color{red}\Box}_i - {\color{red}\Box}_h)({\color{magenta}\Box}_i - {\color{magenta}\Box}_h)]\\
  &= \dfrac{\sum\limits_{i=1}^R ({\color{red}\Box}_i - {\color{red}\Box}_h)({\color{magenta}\Box}_i - {\color{magenta}\Box}_h) m_i}{m_h}\\
  &= \frac{1}{m_h}\sum\limits_{i=1}^R({\color{red}\Box}_i{\color{magenta}\Box}_i m_i) - {\color{red}\Box}_h{\color{magenta}\Box}_h
\end{align}$

***

**Expected Relativity given HG**

$\begin{align}
  \mathrm{E}[{\color{blue}\boxdot} | i] = \mathrm{E}[{\color{red}\Box}] &+ b_{\color{blue}\boxdot}(V_i - \mathrm{E}[V])\\
  &+ c_{\color{blue}\boxdot}(W_i - \mathrm{E}[W])\\
  &+ d_{\color{blue}\boxdot}(X_i - \mathrm{E}[X])\\
  &+ e_{\color{blue}\boxdot}(Y_i - \mathrm{E}[Y])
\end{align}$

## Calculating Expected Excess Losses  
<a name="xsloss"></a>

***Expected XS losses at limit $L$ for class $i$ for injury type (${\color{green}\boxtimes}$)***

<span style="color:red; background-color:yellow">Memorize Formula</span>

$\begin{array}{lllll}
  \mathrm{E}[XSLoss_{ {\color{red}\Box},i}(L)] &= &\dfrac{\text{payroll}_i}{100} & &\cdots (1)\\
  & &\times \: \text{Frequency}_{TT,i} &\times \: \hat{ {\color{blue}\boxdot}_i} &\cdots (2)\\
  & &\times \: \text{Severity}_{TT,i} &\times \: \text{SeverityRel}_{ {\color{red}\Box},i} &\cdots (3)\\
  & &\times \: (1 - \text{LER}_{ {\color{red}\Box},i}(L)) & &\cdots (4) \\
\end{array}$

$(1)$ Exposure

$(2)$ Frequencey based on $Freq_{TT}$ and credibility weighted relativity

$(3)$ Severity based on $Sev_{TT}$ and relativity

* $\text{SeverityRel}_{ {\color{red}\Box},i} = \dfrac{\text{Severity}_{\color{red}\Box}}{\text{Severity}_{TT}} \text{ for class }i$

$(4)$ XS Ratio 

* $\text{LER}_{ {\color{red}\Box},i}(L) =$ Loss Elimination Ratio at limit $L$ for ${\color{green}\boxtimes}$ in class $i$

***

***Expected XS losses at limit $L$ for class $i$***

$\mathrm{E}[XSLoss_i(L)] =\sum\limits_{\color{red}\Box} \mathrm{E}[XSLoss_{ {\color{red}\Box},i}(L)]$

## Testing the Results

Test if there is an improvement in the estimate for injury type ratios
  
Compare the 3 different options on calculating the injury type ratios:

* HG injury type ratios (e.g. $V_h$)
* Raw sample data injury type ratios (e.g. $V_i$)
* Credibility procedure (e.g. $\hat{v}_i$)

See which one best predict the injury type ratios for the holdout sample results using the data from the training set (split by even and odd years)

Injury type ratios for the holdout sample are calculated just like the raw sample

### Sum of Squared Error Tests  
<span style="color:red;background-color:yellow">Memorize</span>
<a name="SSE"></a>

$\begin{array}{lll}
  \text{HG Method:} &SSE_h &= \sum({\color{red}\Box}_h - {\color{red}\Box}_{holdout})^2\\
  \text{Raw Sample Method:} &SSE_{raw} &= \sum({\color{red}\Box}_i - {\color{red}\Box}_{holdout})^2\\
  \text{Credibility Proc Method:} &SSE_{cred} &= \sum(\hat{ {\color{blue}\boxdot}}_i - {\color{red}\Box}_{holdout})^2
\end{array}$

For each injury type ${\color{red}\Box}$ and HG $h$, calculate the above over all classes $i$

Credibility Proc has the lowest SSE but not by much  
Justification:

* Estimators derived from the even year data are designed to fit that data
* Class data by year is volatile

### Quintiles Test  
 <span style="color:red;background-color:yellow">Know</span>  
 <a name="quintiles"></a>

Procedure (for each combination of injury type and HG):

1. **Sort** the **injury type relativities** produced by the credibility proc for **all classes** in **increasing** order (i.e. sort the $\hat{ {\color{blue}\boxdot}}_i$)

2. Use results from 1. to classify classes into quintiles

3. Group classes into **5 quintiles**
    
    * Each quintile should have **about the same number of TT claims**
    
    * Same class can be in different quintiles for different injury types
    
    * For a given injury type, the class will be in the same quintile in the holdout sample as it is from the modeled dataset <span style="color:red">Not sure what this means</span>
    
4. $\forall$ quintile, calculate $\dfrac{\overline{\text{injury type relativity}}_{class}}{\text{injury type relativity}_{HG}}$
    
    * Do this for all 3 methods and the holdout sample with their respective relativities
    
5. Calculate the SSE:  
<span style="color:red; background-color:yellow">Memorize</span>  
$\begin{array}{lll}
  \text{HG Method:} &SSE_h &= \sum\limits_{quintiles}(1 - \dfrac{ {\color{red}\Box}_{holdout, quintile}^*}{ {\color{red}\Box}_{holdout, h}})^2\\
  \text{Raw Sample Method:} &SSE_{raw} &= \sum\limits_{quintiles}(\dfrac{ {\color{red}\Box}_{i,quintile}^*}{ {\color{red}\Box}_{h}} - \dfrac{ {\color{red}\Box}_{holdout, quintile}^*}{ {\color{red}\Box}_{holdout, h}})^2\\
  \text{Credibility Proc Method:} &SSE_{cred} &= \sum\limits_{quintiles}(\dfrac{\hat{ {\color{blue}\boxdot}}_{i, quintile}^*}{ {\color{red}\Box}_{h}} - \dfrac{ {\color{red}\Box}_{holdout, quintile}^*}{ {\color{red}\Box}_{holdout, h}})^2
\end{array}$

    * Note the \* represents the average of the injury type ratio in that quintile
    * $i$ can be dropped since we're now looking a quintile level data
    
6. The method with the lowest SSE = best
    
    * Use this method’s injury type ratio for that particular injury for that particular class <span style="color:red">Not sure what this means</span>
    
This showed substantial reduction in the SSE

* Just means that using quintile injury type ratios is more accurate than HG level ratios, but not necessarily that the procedure is appropriate for class-level estimation

Note that if the classes in a HG are very homogeneous $\Rightarrow$ The injury type ratios won't vary much within that HG $\Rightarrow$ Cred Proc won't have much of an improvement